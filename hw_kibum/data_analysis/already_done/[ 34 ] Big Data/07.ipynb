{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW2ZO44pqRwI"
      },
      "source": [
        "# RDD 최적화 예제\n",
        "\n",
        "이 노트북은 Apache Spark RDD의 최적화 기법들을 설명합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Paa5zQR7qRwJ"
      },
      "source": [
        "## 환경 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0y8trvZqRwK"
      },
      "outputs": [],
      "source": [
        "#!sudo apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.4/spark-3.2.4-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.4-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "iXqFSKeZqRwK"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init(\"/content/spark-3.2.4-bin-hadoop3.2\")\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAiOgxK4qRwL"
      },
      "source": [
        "## 1. Persist/Cache 활용\n",
        "\n",
        "여러 번 사용되는 RDD는 메모리에 캐시하여 재계산을 방지합니다.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "사용법:\n",
        "rdd_cached = rdd.cache()\n",
        "\n",
        "사용 예시:\n",
        "반복적인 알고리즘에서 동일한 RDD를 여러 번 사용할 때\n",
        "대화형 분석에서 동일한 데이터셋을 반복 조회할 때\n",
        "복잡한 변환 연산 후 결과를 여러 번 사용할 때\n",
        "```\n",
        "\n",
        "\n",
        "공식 도큐먼트: \\\n",
        "https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.cache.html \\\n",
        "https://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-persistence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsqLgvi1qRwL",
        "outputId": "f4b7c880-94bc-4b0b-f036-77e94522e0f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without caching:\n",
            "Iteration 1 time: 1.2308361530303955 sec\n",
            "Iteration 2 time: 1.212766408920288 sec\n",
            "Iteration 3 time: 1.3975341320037842 sec\n",
            "\n",
            "With caching:\n",
            "Iteration 1 time: 1.6457555294036865 sec\n",
            "Iteration 2 time: 1.5648951530456543 sec\n",
            "Iteration 3 time: 2.511554718017578 sec\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# 데이터셋 설정\n",
        "numbers = sc.parallelize(range(1, 100000))\n",
        "# TODO: 위 설명을 참고하여 numbers를 캐시하세요\n",
        "numbers_cached = sc.parallelize(range(1, 100000)).cache()\n",
        "\n",
        "# 캐시되지 않은 RDD로 여러 번 반복\n",
        "print(\"Without caching:\")\n",
        "for i in range(3):\n",
        "    start_time = time.time()\n",
        "    sum_val = numbers.sum()\n",
        "    mean_val = numbers.mean()\n",
        "    max_val = numbers.max()\n",
        "    end_time = time.time()\n",
        "    print(f\"Iteration {i+1} time:\", end_time - start_time, \"sec\")\n",
        "\n",
        "print(\"\\nWith caching:\")\n",
        "# 첫 번째 실행에서 캐싱\n",
        "_ = numbers_cached.count()  # 캐싱 강제 실행\n",
        "\n",
        "# 캐시된 RDD로 여러 번 반복\n",
        "for i in range(3):\n",
        "    start_time = time.time()\n",
        "    sum_val = numbers_cached.sum()\n",
        "    mean_val = numbers_cached.mean()\n",
        "    max_val = numbers_cached.max()\n",
        "    end_time = time.time()\n",
        "    print(f\"Iteration {i+1} time:\", end_time - start_time, \"sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 결과를 분석해보면 흥미로운 점이 있습니다:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "캐시되지 않은 RDD:\n",
        "\n",
        "첫 번째 반복: 36.54초 (매우 긴 시간)\n",
        "두 번째 반복: 1.20초\n",
        "세 번째 반복: 1.34초\n",
        "\n",
        "\n",
        "캐시된 RDD:\n",
        "\n",
        "첫 번째 반복: 1.42초\n",
        "두 번째 반복: 1.75초\n",
        "세 번째 반복: 1.54초\n",
        "```\n",
        "\n",
        "\n",
        "여기서 볼 수 있는 특이한 점은:\n",
        "\n",
        "캐시되지 않은 RDD의 첫 번째 실행이 매우 느린 반면, 이후 실행은 오히려 캐시된 버전과 비슷하거나 더 빠릅니다. 이는 Spark나 시스템 레벨에서 자체적인 최적화가 일어나고 있음을 의미합니다.\n",
        "\n",
        "조금 더 정확한 비교를 위해 복잡한 연산을 추가해보겠습니다."
      ],
      "metadata": {
        "id": "oxCh5pTbsmYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# 더 복잡한 연산을 수행하는 함수\n",
        "def complex_operation(x):\n",
        "    # 의도적으로 복잡한 연산 추가\n",
        "    result = x\n",
        "    for _ in range(10):\n",
        "        result = (result * 2) % 100000\n",
        "    return result\n",
        "\n",
        "# 복잡한 연산 사용\n",
        "numbers = sc.parallelize(range(1, 100000))\n",
        "numbers_transformed = numbers.map(complex_operation)\n",
        "# TODO: 위 설명을 참고하여 numbers를 캐시하세요\n",
        "numbers_cached = numbers.map(complex_operation).cache()\n",
        "\n",
        "print(\"Without caching:\")\n",
        "for i in range(3):\n",
        "    start_time = time.time()\n",
        "    # 여러 연산 수행\n",
        "    sum_val = numbers_transformed.sum()\n",
        "    count_val = numbers_transformed.count()\n",
        "    max_val = numbers_transformed.max()\n",
        "    end_time = time.time()\n",
        "    print(f\"Iteration {i+1} time: {end_time - start_time:.2f} sec\")\n",
        "\n",
        "print(\"\\nWith caching:\")\n",
        "# 첫 번째 실행에서 캐싱\n",
        "_ = numbers_cached.count()\n",
        "\n",
        "for i in range(3):\n",
        "    start_time = time.time()\n",
        "    # 여러 연산 수행\n",
        "    sum_val = numbers_cached.sum()\n",
        "    count_val = numbers_cached.count()\n",
        "    max_val = numbers_cached.max()\n",
        "    end_time = time.time()\n",
        "    print(f\"Iteration {i+1} time: {end_time - start_time:.2f} sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQTEQX3Rqh1v",
        "outputId": "c8863448-fc24-4210-930a-f354cb0d3c5c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without caching:\n",
            "Iteration 1 time: 2.29 sec\n",
            "Iteration 2 time: 1.68 sec\n",
            "Iteration 3 time: 1.17 sec\n",
            "\n",
            "With caching:\n",
            "Iteration 1 time: 0.78 sec\n",
            "Iteration 2 time: 0.79 sec\n",
            "Iteration 3 time: 0.84 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "성능 차이가 발생하는 이유:\n",
        "\n",
        "* 연산 재사용:  \n",
        " * 캐시되지 않은 경우: 매번 complex_operation을 다시 실행\n",
        " * 캐시된 경우: 변환된 결과를 메모리에서 직접 읽음\n",
        "\n",
        "\n",
        "* 데이터 지역성:\n",
        " * 캐시된 데이터는 메모리에 있어 접근이 빠름\n",
        " * 캐시되지 않은 경우는 매번 데이터를 처리하고 변환해야 함\n",
        "\n",
        "\n",
        "* 복잡한 연산의 영향:\n",
        " * complex_operation이 각 요소에 대해 10번의 반복 연산을 수행\n",
        " * 이로 인해 캐싱의 이점이 더 명확하게 드러남"
      ],
      "metadata": {
        "id": "1Nj01afVuczN"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}