{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rxt9bMf3orJ"
   },
   "source": [
    "# [ì‹¤ìŠµ1] LangChainìœ¼ë¡œ ê°„ë‹¨í•œ LLM ì±—ë´‡ ë§Œë“¤ê¸° 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BG_0zjG13zZy"
   },
   "source": [
    "## ì‹¤ìŠµ ëª©í‘œ\n",
    "---\n",
    "- LangChainì„ í™œìš©í•´ì„œ gpt-4o-mini ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ì±—ë´‡ì„ ê°œë°œí•©ë‹ˆë‹¤.\n",
    "- ì§§ì€ Chainì„ êµ¬ì„±í•˜ê³ , ì´ë¥¼ í™œìš©í•´ì„œ ì±—ë´‡ì„ êµ¬í˜„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pS7RvUWi5vJe"
   },
   "source": [
    "## ì‹¤ìŠµ ëª©ì°¨\n",
    "---\n",
    "\n",
    "1. **ChatOpenAI Agent ìƒì„±:** ì‚¬ìš©ìì˜ ì…ë ¥ì— ëŒ€í•œ ChatGPTì˜ gpt-4o-mini ëª¨ë¸ì˜ ë‹µë³€ì„ ë°›ì•„ì˜¤ëŠ” Agentë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "2. **ì±—ë´‡ Chain êµ¬ì„±**: ChatOpenAI Agentë¥¼ ë¹„ë¡¯í•˜ì—¬ ì±—ë´‡ êµ¬í˜„ì— í•„ìš”í•œ Agentë“¤ì„ ì—®ì–´ì„œ ì±—ë´‡ Chainìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "3. **ì±—ë´‡ ì‚¬ìš©**: ì—¬ëŸ¬ë¶„ì´ êµ¬ì„±í•˜ì‹  ì±—ë´‡ì„ ì‚¬ìš©í•´ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-rxhtJI5_D2"
   },
   "source": [
    "## ì‹¤ìŠµ ê°œìš”\n",
    "---\n",
    "\n",
    "LangChainì˜ Chainì„ í™œìš©í•´ì„œ gpt-4o-mini ëª¨ë¸ì„ í™œìš©í•˜ëŠ” ì±—ë´‡ì„ êµ¬í˜„í•˜ê³ , Chainì„ í˜•ì„±í•˜ëŠ” ë°©ë²•ì„ ì´í•´í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. í™˜ê²½ ì„¤ì •\n",
    "- í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_community.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kOsIuLd6EA9"
   },
   "source": [
    "## 1. ChatOpenAI Agent ìƒì„±\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt-4o-mini ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ChatOpenAI Agentë¥¼ ìƒì„±í•©ë‹ˆë‹¤. \n",
    "- ChatOpenAI AgentëŠ” ì‚¬ìš©ìì˜ ì…ë ¥ì„ Ollamaë¥¼ í†µí•´ ë¡œì»¬ì—ì„œ êµ¬ë™í•œ LLMì— ì „ì†¡í•˜ê³ , ê·¸ ë‹µë³€ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "- ë³¸ RAG ê³¼ì •ì—ì„œëŠ” LLMìœ¼ë¡œ ChatOpenAIë¥¼ í™œìš©í•  ê²ƒì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Sw25tx4wW-sO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timeo\\AppData\\Local\\Temp\\ipykernel_15216\\4169580261.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=\"\")\n"
     ]
    }
   ],
   "source": [
    "# ë¨¼ì €, gpt-4o-mini ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ChatOpenAI ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agentë¥¼ êµ¬ì„±í–ˆìœ¼ë‹ˆ, ì´ì œ Agentë¥¼ ì‚¬ìš©í•´ë´…ì‹œë‹¤.\n",
    "\n",
    "### 1-1. Runnable interface\n",
    "\n",
    "LangChainì—ì„œ Chainìœ¼ë¡œ ì—®ì„ ìˆ˜ ìˆëŠ” ëŒ€ë¶€ë¶„ì˜ êµ¬ì„± ìš”ì†Œ (Agent, Tool ë“±..)ëŠ” \"Runnable\" protocolì„ ê³µìœ í•©ë‹ˆë‹¤.\n",
    "- ê´€ë ¨ LangChain API ë¬¸ì„œ: [langchain_core.runnables.base.Runnable â€” ğŸ¦œğŸ”— LangChain 0.1.16](https://api.python.langchain.com/en/stable/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable)\n",
    "\n",
    "Runnable protocolì„ ê³µìœ í•˜ëŠ” êµ¬ì„± ìš”ì†ŒëŠ” ëª¨ë‘ ì•„ë˜ ì„¸ ë©”ì„œë“œë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤:\n",
    "- stream: êµ¬ì„± ìš”ì†Œì˜ ë‹µë³€ì„ ìˆœì°¨ì ìœ¼ë¡œ ë°˜í™˜í•œë‹¤ (stream back)\n",
    "- invoke: ì…ë ¥ëœ ê°’ìœ¼ë¡œ chainì„ í˜¸ì¶œí•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•œë‹¤.\n",
    "- batch: ì…ë ¥ê°’ ë¦¬ìŠ¤íŠ¸ (batch)ë¡œ chainì„ í˜¸ì¶œí•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•œë‹¤.\n",
    "\n",
    "ì˜ˆì‹œë¡œ, ì €í¬ê°€ ë°©ê¸ˆ ì‚¬ìš©í•œ `ChatOpenAI` ClassëŠ” \"Runnable\" í•˜ê¸° ë•Œë¬¸ì— `invoke` ë©”ì„œë“œë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "- invoke() ë©”ì„œë“œë¥¼ í†µí•´ Agent, Chain ë“±ì— ë°ì´í„°ë¥¼ ì…ë ¥í•˜ê³ , ê·¸ ì¶œë ¥ì„ ë°›ì•„ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`invoke` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•´ë´…ì‹œë‹¤. ì—¬ê¸°ì„œëŠ” \"ë‹¹ì‹ ì€ ëˆ„êµ¬ì…ë‹ˆê¹Œ?\" ë¼ëŠ” ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ Agentê°€ OpenAI APIë¥¼ í†µí•´ Mistral 7B ëª¨ë¸ì˜ ë‹µë³€ì„ ë°›ì•„ ì¶œë ¥í•  ê²ƒì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì €ëŠ” AI ì–¸ì–´ ëª¨ë¸ì¸ ChatGPTì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì§ˆë¬¸ì— ë‹µí•˜ê³ , ì •ë³´ ì œê³µ ë° ëŒ€í™”ë¥¼ ë‚˜ëˆ„ëŠ” ë° ë„ì›€ì„ ë“œë¦¬ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 14, 'total_tokens': 58, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_482c22a7bc', 'finish_reason': 'stop', 'logprobs': None}, id='run-c3aa137f-89a1-4736-9f05-16efbd8184bb-0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"ë‹¹ì‹ ì€ ëˆ„êµ¬ì…ë‹ˆê¹Œ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¨ìˆœ í…ìŠ¤íŠ¸ ë¿ë§Œ ì•„ë‹ˆë¼, ì‹œìŠ¤í…œ, ì‚¬ëŒ, AIì˜ ë‹µë³€ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ë¦¬í•˜ì—¬ ì…ë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” LangChainì˜ `SystemMessage`, `HumanMessage` Classë¥¼ í™œìš©í•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ ì…ë‹ˆë‹¤.\"),\n",
    "    HumanMessage(\"ë‹¹ì‹ ì„ ì†Œê°œí•´ì£¼ì„¸ìš”.\"),\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— 'ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸' ë¼ëŠ” ì—­í• ì„ ëª…ì‹œí•˜ì˜€ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ì œ gpt-4o-mini ëª¨ë¸ì´ ì•„ê¹Œì™€ ê°™ì€ ì§ˆë¬¸ì— ì–´ë–»ê²Œ ë‹µí–ˆëŠ”ì§€ í™•ì¸í•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì§ˆë¬¸ì— ë‹µí•˜ê³ , ì •ë³´ë¥¼ ì œê³µí•˜ë©°, ì—¬ëŸ¬ë¶„ì˜ í•„ìš”í•œ ë„ì›€ì„ ë“œë¦¬ê¸° ìœ„í•´ ì—¬ê¸° ìˆìŠµë‹ˆë‹¤. í•™ìŠµí•œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì—¬ëŸ¬ ì£¼ì œì— ëŒ€í•´ ëŒ€í™”í•  ìˆ˜ ìˆìœ¼ë©°, ì–¸ì œë“ ì§€ ê¶ê¸ˆí•œ ì ì´ë‚˜ í•„ìš”í•œ ì •ë³´ê°€ ìˆìœ¼ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 31, 'total_tokens': 100, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_482c22a7bc', 'finish_reason': 'stop', 'logprobs': None}, id='run-5d2a8609-06c6-4b31-95ec-f80a4aea75ad-0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê°™ì€ ì§ˆë¬¸ì„ í–ˆìŒì—ë„ ìì‹ ì„ ì†Œê°œí•˜ëŠ” ë¬¸êµ¬ê°€ ì¡°ê¸ˆ ë‹¬ë¼ì§„ ê²ƒ ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [TODO] ë‹¤ì–‘í•œ ì—­í• ì„ ì ìš©í•´ì„œ ì–´ë–»ê²Œ ë‹µë³€ì´ ë‹¬ë¼ì§€ëŠ”ì§€ ììœ ë¡­ê²Œ ì‹¤í—˜í•´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"êµ­í† êµí†µë¶€ ì§ì›\"\n",
    "messages = [\n",
    "    SystemMessage(f\"ë‹¹ì‹ ì€ {role} ì…ë‹ˆë‹¤.\"),\n",
    "    HumanMessage(\"ë‹¹ì‹ ì„ ì†Œê°œí•´ì£¼ì„¸ìš”.\"),\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” êµ­í† êµí†µë¶€ì˜ ì§ì›ìœ¼ë¡œ, êµí†µ, êµ­í†  ê°œë°œ, ì£¼íƒ ì •ì±… ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. êµ­ë¯¼ì˜ ì•ˆì „í•˜ê³  í¸ë¦¬í•œ ìƒí™œì„ ìœ„í•´ ì •ì±…ì„ ê°œë°œí•˜ê³ , ê´€ë ¨ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ì‹  ë¶€ë¶„ì´ ìˆë‹¤ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 28, 'total_tokens': 105, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_482c22a7bc', 'finish_reason': 'stop', 'logprobs': None}, id='run-ecc7183b-ce5d-4e56-bbe0-deb80d26d7e3-0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcAdeSLwcN61"
   },
   "source": [
    "## ì±—ë´‡ Chain êµ¬ì„±\n",
    "\n",
    "ì¡°ê¸ˆ ì „ `llm` objectì˜ ë°˜í™˜ ê°’ì„ í™•ì¸í•´ë³´ë©´, ë‹¤ë¥¸ ì±—ë´‡ì„ ì“¸ ë•Œ ì²˜ëŸ¼ ë‹µë³€ë§Œ ì¶œë ¥ëœ ê²ƒì´ ì•„ë‹ˆë¼ ë‹¤ì–‘í•œ ë©”íƒ€ ë°ì´í„° ê¹Œì§€ ê°™ì´ ì¶œë ¥ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì €í¬ê°€ ChatGPTë¥¼ ì“¸ ë•Œë¥¼ ìƒê°í•´ë³´ë©´, ì±—ë´‡ì— ì´ê±¸ ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ëŠ”ê±´ ì¢€ ë¶€ìì—°ìŠ¤ëŸ½ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´, ë‹µë³€ì„ parsingí•˜ëŠ” `StrOutputParser`ë¥¼ ì‹¤ìŠµ 2ì—ì„œ í™œìš©í•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ì¸ê³µì§€ëŠ¥ í”„ë¡œì íŠ¸ í…œí”Œë¦¿",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
