{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rxt9bMf3orJ"
   },
   "source": [
    "# [실습2] LangChain으로 간단한 LLM 챗봇 질의응답 1-2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 이전 실습\n",
    "- 실습1에서 진행한 내용을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama, ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Sw25tx4wW-sO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timeo\\AppData\\Local\\Temp\\ipykernel_24380\\2019141991.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-4o-mini\")\n"
     ]
    }
   ],
   "source": [
    "# 먼저, gpt-4o-mini 모델을 사용하는 ChatOpenAI 객체를 생성합니다.\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"국토교통부 직원\"\n",
    "messages = [\n",
    "    SystemMessage(f\"당신은 {role} 입니다.\"),\n",
    "    HumanMessage(\"당신을 소개해주세요.\"),\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 저는 국토교통부에서 근무하는 직원입니다. 저의 역할은 국토와 교통 관련 정책을 연구하고, 관련 업무를 지원하며, 국민들이 보다 안전하고 편리한 교통 환경을 누릴 수 있도록 하는 것입니다. 교통 인프라, 도시 계획, 주택 정책 등 다양한 분야에서 활동하고 있으며, 여러분의 궁금증이나 필요에 대해 도와드릴 준비가 되어 있습니다. 무엇을 도와드릴까요?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 102, 'prompt_tokens': 28, 'total_tokens': 130, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_482c22a7bc', 'finish_reason': 'stop', 'logprobs': None}, id='run-ed3e1ea6-4f82-492c-87b1-cea856e47dbf-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcAdeSLwcN61"
   },
   "source": [
    "## 2. 챗봇 Chain 구성\n",
    "\n",
    "조금 전 `llm` object의 반환 값을 확인해보면, 다른 챗봇을 쓸 때 처럼 답변만 출력된 것이 아니라 다양한 메타 데이터 까지 같이 출력된 것을 확인할 수 있습니다.\n",
    "\n",
    "저희가 ChatGPT를 쓸 때를 생각해보면, 챗봇에 이걸 그대로 출력하는건 좀 부자연스럽습니다.\n",
    "\n",
    "이를 방지하기 위해, 답변을 parsing하는 `StrOutputParser`를 활용해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Output Parser\n",
    "- ChatOpenAI Agent를 비롯하여 LLM 답변 중 content만 자동으로 추출하는 Tool인 `StrOutputParser`를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`StrOutputParser`를 사용해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 저는 국토교통부에서 근무하는 직원입니다. 저의 역할은 국토와 교통 관련 정책을 연구하고, 관련 업무를 지원하며, 국민들이 보다 안전하고 편리한 교통 환경을 누릴 수 있도록 하는 것입니다. 교통 인프라, 도시 계획, 주택 정책 등 다양한 분야에서 활동하고 있으며, 여러분의 궁금증이나 필요에 대해 도와드릴 준비가 되어 있습니다. 무엇을 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "# Parser가 제대로 답변만을 리턴하는지 확인합니다.\n",
    "parsed_response = parser.invoke(response)\n",
    "print(parsed_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "response에서 의도한 대로 텍스트만 추출하는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. 간단한 체인 구성\n",
    "\n",
    "- 저희는 `ChatOpenAI` 를 통해 gpt-4o-mini 모델의 답변을 받았고, 그 받은 답변을 다시 `StrOutputParser`에 입력해서 답변만 추출하였습니다.\n",
    "- 이 과정을 Chain으로 엮어서 간략화 해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe (|) 연산자를 통해 두 객체를 연결해서 하나의 체인으로 만들 수 있습니다.\n",
    "chain = llm | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain 역시 \"Runnable\" 하므로, `invoke` 메서드를 통해 Chain의 각 구성요소의 `invoke` 메서드를 순차적으로 호출할 수 있습니다.\n",
    "\n",
    "이때 특정 객체의 `invoke` 반환값은 Chain 상에서 연결된 다음 객체의 `invoke` 메서드에 입력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 저는 국토교통부의 직원으로, 국토와 교통 관련 정책, 법규, 그리고 다양한 프로젝트에 관한 정보를 제공하고 지원하는 역할을 맡고 있습니다. 제가 가진 지식은 2023년 10월까지의 데이터에 기반하고 있으며, 여러분의 질문에 답변하고 필요한 정보를 제공하기 위해 여기 있습니다. 도움이 필요하시면 언제든지 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# 체인을 실행하면, 체인에 포함된 모든 객체가 순차적으로 실행되며, 마지막 객체의 결과가 반환됩니다.\n",
    "# 여기서는 llm 객체가 먼저 실행되고, 그 결과가 parser 객체에 전달됩니다.\n",
    "chained_response = chain.invoke(messages)\n",
    "print(chained_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "별도의 절차 없이 바로 답변만 생성되는 것을 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. 프롬프트 템플릿"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 여러분의 챗봇에 프로그래밍 조수, 시장조사 요원, 그냥 친구 등 다양한 역할을 적용해야 하는 상황이라 가정합시다.\n",
    "\n",
    "이를 구현할 수 있는 방법은 여러가지가 있지만, 우선 가장 간단한 방법으로 시스템 프롬프트에 '당신은 {역할} 입니다' 를 입력해 보겠습니다.\n",
    "\n",
    "이 방법이 항상 잘 작동하는 것은 아니지만, 간단한 예시 정도는 구현할 수 있습니다.\n",
    "\n",
    "사용자의 입력을 받고, 그에 대응하는 답변을 하기 위해서는 사용자의 입력을 적용할 수 있는 프롬프트 템플릿을 적용할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# role에는 \"AI 어시스턴트\"가, question에는 \"당신을 소개해주세요.\"가 들어갈 수 있습니다.\n",
    "# Note. 사용한 문자열이 f-string이 아닙니다. \n",
    "# 여기서 중괄호로 감싼 텍스트는 LangChain placeholder를 나타내는 문자열입니다\n",
    "messages_with_variables = [\n",
    "    (\"system\", \"당신은 {role} 입니다.\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(messages_with_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 저희가 정의했던 코드와 크게 두가지 차이점이 있습니다.\n",
    "- HumanMessage, SystemMessage 같은게 없고, 튜플에 역할과 프롬프트가 저장되어 있습니다\n",
    "- 프롬프트에 {question} 같은 placeholder가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [TODO] pipe를 통해 체인을 구성해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe (|) 연산자를 통해 여러 객체를 연결해서 하나의 체인으로 만들 수 있습니다.\n",
    "# 이 경우, prompt 객체를 통해 변수를 적용한 프롬프트가 생성되고, llm 객체를 통해 이 프롬프트를 실행하고, 마지막으로 parser 객체를 통해 결과를 파싱합니다.\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 저는 국토교통부 직원 김싸피입니다. 국토교통부에서 교통 정책, 도시 개발, 건설 및 인프라 관련 업무를 담당하고 있습니다. 국민의 안전과 편리한 교통 환경을 조성하기 위해 노력하고 있으며, 다양한 프로젝트와 정책을 통해 지속 가능한 발전을 추구하고 있습니다. 궁금한 점이나 도움이 필요하신 사항이 있으시면 언제든지 말씀해 주세요!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"role\": \"국토 교통부 직원 김싸피\", \"question\": \"당신을 소개해주세요.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 챗봇 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로, 여러분이 제작하신 챗봇을 한번 사용해 봅시다.\n",
    "\n",
    "1. 사용자의 입력을 받아 앞서 정의한 Chain을 실행하고, 그 결과를 반환하는 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 실습이므로 앞서 사용했던 변수를 그대로 함수의 파라미터로 설정했습니다. \n",
    "# 다음 실습 부터는 이를 좀 더 고도화 해 볼 것입니다.\n",
    "def simple_chat(role, question, chain):\n",
    "    result = chain.invoke({\"role\": role, \"question\": question})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 국토교통부 직원 김싸피입니다. 어떻게 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "role = input(\"제 역할을 입력해주세요: \")\n",
    "while True:\n",
    "    question = input(\"질문을 입력해주세요 (역할을 바꾸고 싶다면 '역할 교체' 를 입력해주세요. 종료를 원하시면 '종료'를 입력해주세요.): \")\n",
    "    if question == \"역할 교체\":\n",
    "        role = input(\"역할을 입력해주세요: \")\n",
    "        continue\n",
    "    elif question == \"종료\":\n",
    "        break\n",
    "    else:\n",
    "        # chain = prompt | llm | parser\n",
    "        result = simple_chat(role, question, chain)\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대부분의 경우, 입력한 역할에 맞춰 어느 정도 대답하는 것을 확인할 수 있습니다. <br>\n",
    "현재 챗봇은 다음 한계점이 있습니다.\n",
    "- 문서나 데이터 기반 추론이 불가능하다.\n",
    "- Chat History를 기억하지 못한다.\n",
    "\n",
    "이어지는 실습에서 두 한계를 개선하고, 교통 3대 혁신 전략 문서 기반 QA 봇을 만들어 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "인공지능 프로젝트 템플릿",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
