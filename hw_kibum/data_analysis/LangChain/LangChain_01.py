import os, time

from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.text_splitter import CharacterTextSplitter
from langchain.schema import HumanMessage, SystemMessage

from langchain_community.document_loaders import TextLoader, PyPDFLoader, YoutubeLoader, WebBaseLoader
from langchain_community.vectorstores import FAISS

from langchain_openai.chat_models import ChatOpenAI
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain_openai import OpenAIEmbeddings, OpenAI

from langchain_core.prompts import ChatPromptTemplate

import bs4


"""
pip install langchain langchain-community langchain-openai
pip install youtube-transcript-api pytube  # ì§€ê¸ˆì€ ì‘ë™ ì•ˆí•˜ëŠ”ë“¯? ìœ íŠœë¸Œ ì˜ìƒ ìë§‰ ë°›ì•„ì™€ txtë¡œ í•˜ëŠ” ?

LangChain ë° ê´€ë ¨ ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°
> í…ìŠ¤íŠ¸ ë¶„í• , ë²¡í„° ì €ì¥ì†Œ(FAISS), OpenAI ê¸°ë°˜ ì„ë² ë”©, OpenAI ëŒ€í™” ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.

PyPDFLoader: PDF íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ëŠ” ëª¨ë“ˆ
YoutubeLoader: ìœ íŠœë¸Œ ìë§‰ì„ ë¶ˆëŸ¬ì™€ì„œ ë¬¸ì„œë¡œ ë¡œë“œí•˜ëŠ” ëª¨ë“ˆ
WebBaseLoader: ì›¹ í˜ì´ì§€ì˜ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ëª¨ë“ˆ

ChatOpenAI   : OpenAIì˜ GPT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”ë¥¼ ì²˜ë¦¬í•˜ëŠ” ëª¨ë“ˆ
HumanMessage : ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ì´ë‚˜ ë©”ì‹œì§€ë¥¼ GPT ëª¨ë¸ì— ì „ë‹¬í•˜ê¸° ìœ„í•´ ì‚¬ìš©
SystemMessage: ì‹œìŠ¤í…œì˜ ì—­í• ì„ ì •ì˜í•˜ê³  ëª¨ë¸ì—ê²Œ ì´ˆê¸° ì§€ì¹¨ì„ ì œê³µí•˜ê¸° ìœ„í•´ ì‚¬ìš©
CharacterTextSplitter: ë¬¸ì„œë¥¼ ì—¬ëŸ¬ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸° ìœ„í•œ í…ìŠ¤íŠ¸ ë¶„í• ê¸°
FAISS : í…ìŠ¤íŠ¸ ë°ì´í„° [ ì²­í¬ ] ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
      : ëŒ€ê·œëª¨ ë²¡í„° ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ìœ ì‚¬ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬

OpenAIEmbeddings: [ í…ìŠ¤íŠ¸ > ë²¡í„° ] ë¡œ ë³€í™˜í•˜ëŠ” OpenAI ì„ë² ë”© ëª¨ë¸


TextLoader() ì°¸ê³ : https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/
loader.load() ì°¸ê³ : https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/
FAISS.from_documents() í•¨ìˆ˜ ì°¸ê³ : https://sj-langchain.readthedocs.io/en/latest/vectorstores/langchain.vectorstores.faiss.FAISS.html#langchain.vectorstores.faiss.FAISS.from_documents

OpenAI API í‚¤ ì„¤ì • > TODO: os.environì„ ì‚¬ìš©í•˜ì—¬ "OPENAI_API_KEY"ë¥¼ ì„¤ì •

____________________________________________________________
[ í™˜ê²½ ë³€ìˆ˜(os.environ) ì°¸ê³ : https://docs.python.org/3/library/os.html#os.environ ]
[ cf > ì½”ë“œì— ì§ì ‘ í¬í•¨í•˜ëŠ” ë°©ì‹ vs os.environì„ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ ]
1. ì½”ë“œì— ì§ì ‘ í¬í•¨í•˜ëŠ” ë°©ì‹
ì¥ì : ì½”ë“œë¥¼ ì‹¤í–‰í•  ë•Œë§ˆë‹¤ API í‚¤ë¥¼ ì„¤ì •í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ í¸ë¦¬í•©ë‹ˆë‹¤.
ë‹¨ì : ì½”ë“œì— API í‚¤ê°€ í¬í•¨ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— ë³´ì•ˆìƒ ì·¨ì•½í•©ë‹ˆë‹¤.

2. os.environì„ ì‚¬ìš©í•˜ëŠ” ë°©ì‹
ì¥ì : API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ë¯€ë¡œ ì½”ë“œì— API í‚¤ê°€ í¬í•¨ë˜ì§€ ì•Šì•„ ë³´ì•ˆìƒ ì•ˆì „í•©ë‹ˆë‹¤. ê·¸ë˜ì„œ ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
ë‹¨ì : ì½”ë“œë¥¼ ì‹¤í–‰í•  ë•Œë§ˆë‹¤ API í‚¤ë¥¼ ì„¤ì •í•´ì•¼ í•˜ë¯€ë¡œ ë²ˆê±°ë¡­ìŠµë‹ˆë‹¤.
____________________________________________________________
"""
os.environ["OPENAI_API_KEY"] = ''

# TODO: txt íŒŒì¼ ğŸ”¥
# loader = TextLoader('./data/financial_articles.txt')  # Langchainì˜ TextLoaderë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸ˆìœµ ê¸°ì‚¬ txt íŒŒì¼ì„ ë¡œë“œ
# documents = loader.load()                             # loader.load() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ë‚´ìš©ì„ ë¡œë“œ => ë¡œë“œëœ ë¬¸ì„œë¥¼ documents ë³€ìˆ˜ì— ì €ì¥
#
# for i, doc in enumerate(documents):                   # ê° ë¬¸ì„œì˜ í…ìŠ¤íŠ¸ ê¸¸ì´ì™€ í† í° ìˆ˜ë¥¼ ì¶œë ¥
#     print(f"ë¬¸ì„œ {i+1}ì˜ ê¸¸ì´: {len(doc.page_content)} ë¬¸ì")
#     print(f"ë¬¸ì„œ {i+1}ì˜ í† í° ìˆ˜: {len(doc.page_content.split())} í† í°")
#
# print("\nì²« ë²ˆì§¸ ë¬¸ì„œì˜ ë‚´ìš©:")
# print(documents[0].page_content)                      # ì²« ë²ˆì§¸ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì¶œë ¥
# # _________________________________________________________________________________
# loader = TextLoader("./data/financial_articles.txt")       # 1. ê¸ˆìœµ ê¸°ì‚¬ ë°ì´í„°ë¥¼ ë¡œë“œ
# documents = loader.load()
#
# embedding = OpenAIEmbeddings()                             # 2. OpenAI ì„ë² ë”©ê³¼ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
# vector_store = FAISS.from_documents(documents, embedding)  # FAISS.from_documents() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ vector_store ë³€ìˆ˜ë¥¼ ì´ˆê¸°í™”
#                                                            # documentsì™€ embeddingì„ ì‚¬ìš©í•´ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
#
# llm = OpenAI()                                             # 3. RAG ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•œ ì§ˆë¬¸ ì‘ë‹µ ì‹œìŠ¤í…œ êµ¬ì„±
#
# # í”„ë¡¬í”„íŠ¸ ì„¤ì •
# system_prompt = ("ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. " "ëª¨ë¥´ë©´ 'ëª¨ë¦…ë‹ˆë‹¤'ë¼ê³  ë§í•˜ì„¸ìš”. " "ìµœëŒ€ ì„¸ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”. " "ì»¨í…ìŠ¤íŠ¸: {context}")
# prompt = ChatPromptTemplate.from_messages( [("system", system_prompt), ("human", "{input}"),] )
#
# # ì§ˆë¬¸ ì‘ë‹µ ì²´ì¸ ìƒì„±
# question_answer_chain = create_stuff_documents_chain(llm, prompt)
# qa_chain = create_retrieval_chain(vector_store.as_retriever(), question_answer_chain)
#
# # 4. ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±
# questions = ["ìµœê·¼ ê¸ˆìœµ ì‹œì¥ì˜ ì£¼ìš” ë™í–¥ì€ ë¬´ì—‡ì¸ê°€ìš”?", "ê¸ˆë¦¬ ì¸ìƒì˜ ì˜í–¥ì€ ì–´ë–»ê²Œ ë¶„ì„ë  ìˆ˜ ìˆë‚˜ìš”?", "í˜„ì¬ ì•”í˜¸í™”í ì‹œì¥ì˜ ìƒí™©ì€ ì–´ë–¤ê°€ìš”?"]
#
# for question in questions:  # ê° ì§ˆë¬¸ì— ëŒ€í•´ ë‹µë³€ ìƒì„± ë° ì¶œë ¥
#     print('#################################################################')
#     answer = qa_chain.invoke({"input": question})
#
#     # ê²°ê³¼ì—ì„œ 'answer' í‚¤ë¥¼ ì°¾ê³  ì¶œë ¥, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ 'ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.' ì„¤ì •
#     response = answer.get('answer', 'ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
#     print(f"ì§ˆë¬¸: {question}")
#     print(f"ë‹µë³€: {response}\n")



# TODO: LLM ì´ìš© ğŸ”¥

# # ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ ì •ì˜
# def handle_traffic_query(query_text):
#     llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0) # OpenAIì˜ GPT-4 ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ì‘ì€ ë²„ì „(gpt-4o-mini)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
#     system_message = SystemMessage(content="ë„ˆëŠ” êµí†µ ì •ë³´ ì „ë¬¸ê°€ì•¼. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ êµí†µ ê´€ë ¨ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì¤˜.")  # ëª¨ë¸ì—ê²Œ êµí†µ ì „ë¬¸ê°€ë¡œì„œ ì‘ë‹µí•˜ë„ë¡ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì •
#     human_message = HumanMessage(content=f"êµí†µ ì§ˆë¬¸: {query_text}")  # ì‚¬ìš©ìì˜ êµí†µ ê´€ë ¨ ì§ˆë¬¸ì„ ì „ë‹¬í•˜ëŠ” ë©”ì‹œì§€ ìƒì„±
#     conversation = [system_message, human_message]    # ëŒ€í™”ì— ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ì¶”ê°€
#     response = llm.__call__(conversation)             # ëª¨ë¸ì—ê²Œ ëŒ€í™” í˜•ì‹ìœ¼ë¡œ ì§ˆë¬¸ì„ ë³´ë‚´ê³  ë‹µë³€ì„ ë°›ìŠµë‹ˆë‹¤.
#     return response.content                           # ê²°ê³¼ ë°˜í™˜ (ëª¨ë¸ì˜ ë‹µë³€)
#
# # ì§ˆë¬¸ ì²˜ë¦¬
# traffic_query = "ì„œìš¸ì—ì„œ ë¶€ì‚°ê¹Œì§€ ê³ ì†ë„ë¡œ êµí†µ ìƒí™©ì€ ì–´ë–¤ê°€ìš”?"  # ì˜ˆì‹œ ì§ˆë¬¸ ì„¤ì •
# response = handle_traffic_query(traffic_query)  # ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œ
# print(f"ë‹µë³€:\n {response}")  # ê²°ê³¼ ì¶œë ¥


# TODO: [ì›¹ / PDF] LOAD ğŸ”¥

# # ì•„ë˜ì˜ load_traffic_dataë§Œ êµì²´í•´ì£¼ë©´ ë˜‘ê°™ì€ ë™ì‘ í•¨
# # ì›¹ì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜ - ì£¼ì–´ì§„ ì›¹ í˜ì´ì§€ URLì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
# def load_traffic_news(url):
#     loader = WebBaseLoader(url)                                 # ì›¹ ë¡œë” ìƒì„±
#     documents = loader.load()                                   # ì›¹ í˜ì´ì§€ì—ì„œ ë¬¸ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
#     print(f"{len(documents)}ê°œì˜ í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")  # ë¡œë“œëœ ë¬¸ì„œ ìˆ˜ ì¶œë ¥
#     return documents                                            # ë¡œë“œëœ ë¬¸ì„œ ë°˜í™˜

# # PDF íŒŒì¼ ë¡œë“œ í•¨ìˆ˜ - PDF íŒŒì¼ì„ ë¡œë“œí•´ í…ìŠ¤íŠ¸ ì¶”ì¶œ > ê° í˜ì´ì§€ê°€ í•˜ë‚˜ì˜ ë¬¸ì„œë¡œ ë°˜í™˜
# def load_traffic_data(pdf_file_path):
#     loader = PyPDFLoader(pdf_file_path)                         # PDF ë¡œë” ìƒì„±
#     documents = loader.load()                                   # PDFì—ì„œ ë¬¸ì„œ(í˜ì´ì§€) ë¶ˆëŸ¬ì˜¤ê¸°
#     print(f"{len(documents)}ê°œì˜ í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")  # í˜ì´ì§€ ìˆ˜ ì¶œë ¥
#     return documents                                            # ë¡œë“œëœ ë¬¸ì„œ ë°˜í™˜
#

# # ë¬¸ì„œë¥¼ ì¼ì • í¬ê¸°ì˜ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ëª¨ë¸ì´ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ëŠ” í•¨ìˆ˜
# def split(documents):
#     # ì²­í¬ë¥¼ ë¶„í• í•  ë•Œ ì‚¬ìš©í•  êµ¬ë¶„ì (ì¤„ë°”ê¿ˆ ê¸°ì¤€) / í•œ ì²­í¬ì˜ ìµœëŒ€ ê¸¸ì´ (ë‹¨ìœ„: ë¬¸ì ìˆ˜) /  ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¶€ë¶„ ê¸¸ì´ (ì¤‘ë³µëœ ë¶€ë¶„ì„ í¬í•¨í•˜ì—¬ ë¬¸ë§¥ ìœ ì§€)
#     text_splitter = CharacterTextSplitter(separator="\n", chunk_size=300, chunk_overlap=100)
#     splits = text_splitter.split_documents(documents)  # ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
#     print(f"{len(splits)}ê°œì˜ ì²­í¬ë¡œ ë‚˜ëˆ„ì—ˆìŠµë‹ˆë‹¤.")       # ì²­í¬ ìˆ˜ ì¶œë ¥
#     return splits                                       # ë‚˜ëˆˆ ì²­í¬ ë°˜í™˜
#
# # ì²­í¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜ - OpenAI ì„ë² ë”©ì„ ì‚¬ìš©í•´ ì²­í¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ê³ , FAISS ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥
# def store_in_vector_db(splits):
#     embeddings = OpenAIEmbeddings()                          # OpenAI ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
#     vector_store = FAISS.from_documents(splits, embeddings)  # ì²­í¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ê³  ì €ì¥
#     print("ë²¡í„° ìŠ¤í† ì–´ì— ì²­í¬ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")                   # ì €ì¥ ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥
#     return vector_store                                      # ë²¡í„° ìŠ¤í† ì–´ ë°˜í™˜
#
# # ì…ë ¥í•œ ì§ˆë¬¸(query)ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜
# def retrieve_similar_docs(query_text, vector_store):
#     docs = vector_store.similarity_search(query_text, k=3)  # ìœ ì‚¬ë„ ë†’ì€ ìƒìœ„ 3ê°œì˜ ë¬¸ì„œ ê²€ìƒ‰
#     print("ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤.")                        # ê²€ìƒ‰ ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥
#     return docs                                             # ê²€ìƒ‰ëœ ë¬¸ì„œ ë°˜í™˜
#
# # ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
# def generate_answer(query_text, docs):
#     llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)   # OpenAIì˜ GPT-4 ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
#     system_message = SystemMessage(content="ë„ˆëŠ” êµí†µ ì „ë¬¸ê°€ì•¼. ì§ˆë¬¸ì— ëŒ€í•´ ê´€ë ¨ëœ êµí†µ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì¤˜.")  # ëª¨ë¸ì˜ ì—­í• ì„ ì§€ì • (êµí†µ ì „ë¬¸ê°€)
#     human_message = HumanMessage(content=f"ì§ˆë¬¸: {query_text}\n\n{docs}")  # ì§ˆë¬¸ê³¼ ê²€ìƒ‰ëœ ë¬¸ì„œë¡œ ìœ ì € ë©”ì‹œì§€ ìƒì„±
#     conversation = [system_message, human_message]             # ëŒ€í™”ì— ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ìœ ì € ì§ˆë¬¸ ì¶”ê°€
#     response = llm.__call__(conversation)                      # ëª¨ë¸ì—ê²Œ ëŒ€í™” ì „ë‹¬í•˜ì—¬ ë‹µë³€ ìƒì„±
#     return response.content                                    # ìƒì„±ëœ ë‹µë³€ ë°˜í™˜
#
# ## Main - íƒ 1

# pdf_file_path = "./data/êµí†µ_3ëŒ€_í˜ì‹ _ì „ëµ.pdf"  # PDF íŒŒì¼ ê²½ë¡œ ì„¤ì •
# query_text = "GTXì˜ Aë…¸ì„ ì˜ êµ¬ê°„ì€?"              # ê²€ìƒ‰í•  ì§ˆë¬¸ ì„¤ì •
# documents = load_traffic_data(pdf_file_path)                    # 1. Loading: PDF íŒŒì¼ì—ì„œ ë¬¸ì„œ ë¡œë“œ
#
# url = "https://www.ohmynews.com/NWS_Web/View/at_pg.aspx?CNTN_CD=A0003069986&CMPT_CD=P0010&utm_source=naver&utm_medium=newsearch&utm_campaign=naver_news"  # ì›¹ í˜ì´ì§€ URL ì„¤ì •
# documents = load_traffic_news(url)
# query_text = "ì°¨ëŸ‰ì‹ í˜¸ê°€ ë…¹ìƒ‰ì¸ ê²½ìš° ìš°íšŒì „ì€ ì–´ë–»ê²Œ í•´ì•¼í•´?"  # ê²€ìƒ‰í•  ì§ˆë¬¸ ì„¤ì •
#
#
# splits = split(documents)                                       # 2. Splitting: ë¬¸ì„œë¥¼ ì—¬ëŸ¬ ì²­í¬ë¡œ ë¶„í• 
# vector_store = store_in_vector_db(splits)                       # 3. Storage : ì²­í¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ í›„ ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥
# similar_docs = retrieve_similar_docs(query_text, vector_store)  # 4. Retrieval: ì§ˆë¬¸ì— ëŒ€í•œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
# answer = generate_answer(query_text, similar_docs)              # 5. Generation: ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„±
# print(f"ìµœì¢… ë‹µë³€: {answer}")                                    # ìµœì¢… ê²°ê³¼ ì¶œë ¥ (ëª¨ë¸ì´ ìƒì„±í•œ ë‹µë³€ ì¶œë ¥)




# TODO: [ìœ íŠœë¸Œ ìë§‰] LOAD ğŸ”¥

# # ìœ íŠœë¸Œ ìë§‰ì„ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜ - ìœ íŠœë¸Œ URLì„ ì…ë ¥ë°›ì•„ ìë§‰ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ , ì„±ê³µí•  ë•Œê¹Œì§€ ì¬ì‹œë„
# def load_youtube_transcript(url, add_video_info=True, max_retries=5, retry_delay=2):
#     attempts = 0  # ì‹œë„ íšŸìˆ˜ ì´ˆê¸°í™”
#     while attempts < max_retries:  # ìµœëŒ€ ì‹œë„ íšŸìˆ˜ê¹Œì§€ ë°˜ë³µ
#         try:
#             # ìœ íŠœë¸Œ ìë§‰ ë¡œë”ë¥¼ URLì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„± -                   ë¹„ë””ì˜¤ ì •ë³´ í¬í•¨ ì—¬ë¶€ / í•œêµ­ì–´ì™€ ì˜ì–´ ìë§‰ ì§€ì›
#             loader = YoutubeLoader.from_youtube_url(url, add_video_info=add_video_info, language=['ko', 'en'],)
#             documents = loader.load()                           # ìœ íŠœë¸Œ ìë§‰ ë¡œë“œ
#             print(f"ìœ íŠœë¸Œ ìë§‰ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
#             return documents                                    # ì„±ê³µ ì‹œ ë¡œë“œëœ ë¬¸ì„œ ë°˜í™˜
#         except Exception as e:                                  # ì˜¤ë¥˜ ë°œìƒ ì‹œ
#             attempts += 1                                       # ì‹œë„ íšŸìˆ˜ ì¦ê°€
#             print(f"ìœ íŠœë¸Œ ìë§‰ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. {retry_delay}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤. (ì‹œë„ {attempts}/{max_retries})")
#             time.sleep(retry_delay)                             # ì¬ì‹œë„ ì „ ëŒ€ê¸°
#     print("ìµœëŒ€ ì‹œë„ íšŸìˆ˜ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ìë§‰ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
#     return None                                                 # ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
#
#
# # LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„± - ë¶ˆëŸ¬ì˜¨ ìœ íŠœë¸Œ ìë§‰ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
# def generate_answer(query_text, docs):
#     llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)    # OpenAIì˜ GPT-4 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
#     system_message = SystemMessage(content="ë„ˆëŠ” ìœ íŠœë¸Œ ìë§‰ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì—­í• ì„ í•œë‹¤.")  # ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ í†µí•´ ëª¨ë¸ì˜ ì—­í• ì„ ì§€ì • (ìë§‰ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ì—­í• )
#     human_message = HumanMessage(content=f"ì§ˆë¬¸: {query_text}\n\n{docs}")    # ìœ ì €ì˜ ì§ˆë¬¸ì„ ë‹´ì€ ë©”ì‹œì§€ ìƒì„±
#     conversation = [system_message, human_message]    # ëŒ€í™”ì— ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ìœ ì € ì§ˆë¬¸ ì¶”ê°€
#     response = llm.__call__(conversation)    # ëª¨ë¸ì—ê²Œ ëŒ€í™”ë¥¼ ì „ë‹¬í•˜ì—¬ ë‹µë³€ ìƒì„±
#     return response.content  # ìƒì„±ëœ ë‹µë³€ ë°˜í™˜
#
# # Main : ìœ íŠœë¸Œ ìë§‰ì´ ìˆëŠ” êµí†µ ë‰´ìŠ¤ ì˜ìƒ URLê³¼ ì§ˆë¬¸ì„ ì„¤ì •
# url = "https://www.youtube.com/watch?v=_8w803FPWmw"  # ìœ íŠœë¸Œ ì˜ìƒ URL (êµí†µ ë‰´ìŠ¤)
# query_text = "ì´ ë‰´ìŠ¤ì˜ ì£¼ìš” ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?"         # ìœ ì €ê°€ ë¬»ëŠ” ì§ˆë¬¸
# documents = load_youtube_transcript(url)         # 1. Loading: ìœ íŠœë¸Œ ìë§‰ì„ ë¡œë“œ
# answer = generate_answer(query_text, documents)  # 2. Generation: ìë§‰ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±
# print(f"ìµœì¢… ë‹µë³€: {answer}")                     # ëª¨ë¸ì´ ìƒì„±í•œ ìµœì¢… ë‹µë³€ ì¶œë ¥
