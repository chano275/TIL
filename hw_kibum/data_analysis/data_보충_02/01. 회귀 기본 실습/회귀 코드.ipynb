{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zK2KgotpHJZy"
   },
   "source": [
    "# 머신러닝 회귀모델 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZGO2fuNHJZ7"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZAfl91IHJZ7"
   },
   "source": [
    "## 실습 목표\n",
    "- 머신러닝 다양한 모델을 활용하여 회귀분석을 진행해봅니다.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDBuglSEHJZ8"
   },
   "source": [
    "## 실습 목차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZcZu4Opbeos"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "-  **회귀분석 실습** : **LinearRegression, KNN, SVM, AdaBoost, Bagging, RandomForest** 등 다양한 모델을 구현하는 실습을 진행해봅니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 및 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리 완료한 데이터를 불러옵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**InkjetDB_preprocessing.csv 설명**\n",
    "\n",
    "PrintingNum,Viscosity,Velocity,PrintingSpeed 총 4개의 Feature를 이용해서 \n",
    "PatternSize의 값을 회귀예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './'\n",
    "df = pd.read_csv(os.path.join(data_dir, 'InkjetDB_preprocessing.csv'))\n",
    "\n",
    "X = df.drop(['PatternSize'], axis=1)\n",
    "y = df['PatternSize']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0w9M2E8fRhd"
   },
   "source": [
    "## 머신러닝 회귀분석 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7siOKwJvhILb"
   },
   "source": [
    "### 학습 및 테스트 데이터세트 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ac_4iknbhLz_"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1661002105572,
     "user": {
      "displayName": "김도현",
      "userId": "01074377609887751305"
     },
     "user_tz": -540
    },
    "id": "RQ59qV9thNAV",
    "outputId": "93305088-11fa-4902-ac2b-6622fab967c5"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size = 0.2, random_state = 1)\n",
    "X.shape\n",
    "print('학습 데이터 :' ,X_train.shape)\n",
    "print('테스트 데이터 : ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AR6jLrA3gydP"
   },
   "source": [
    "### 선형 회귀(Linear Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJzU2-hihDNQ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TofO3-xJho5C"
   },
   "source": [
    "먼저 선형회귀를 이용해 회귀분석을 진행해보겠습니다. 평가지표는 결정계수와 평균제곱근오차(RMSE)를 사용합니다. \n",
    "\n",
    "- **결정계수 ($R^2$)** : 독립 변수가 종속 변수를 얼마나 잘 설명해주는지 보여주는 지표입니다\n",
    "- **평균제곱근오차** : 추정 값 또는 모델이 예측한 값과 실제 환경에서 관찰되는 값의 차이를 다룰 때 흔히 사용하는 측도로 정밀도(precision)를 표현하는데 적합 각각의 차이값은 잔차(residual)라고도 하며, 평균 제곱근 편차는 잔차들을 하나의 측도로 종합할 때 사용합니다.\n",
    "\n",
    "- X가 Y와의 상관관계가 클수록 $R^2$의 값은 1에 가까워집니다.\n",
    "- ($R^2$≥0.65)정도가 되어야 의미있는 회귀식으로 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기본 회귀 모델 학습 - 선형 회귀 모델\n",
    "\n",
    "선형 회귀 모델을 학습시켜보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주요 파라미터\n",
    "- fit_intercept: 절편을 포함할지 여부를 결정합니다. True일 경우 모델은 절편을 학습하고, False일 경우 데이터가 원점을 지나도록 강제합니다.\n",
    "- n_jobs: 병렬 처리할 작업 수를 지정합니다. -1로 설정하면 가능한 모든 CPU 코어를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# 선형 회귀 모델 정의\n",
    "model = LinearRegression(fit_intercept=True, n_jobs=1)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 결정 계수 계산\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# 평균 제곱근 오차 계산\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"결정 계수:\", r2)\n",
    "print(\"평균 제곱근 오차:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가를 마친 이후, 시각화 코드를 통해 실제값과 예측값의 차이를 확인해봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 모델의 출력값\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 그래프로 시각화\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--', lw=2)  # 일치하는 직선\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs. Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5voOgwt7n-K"
   },
   "source": [
    "### KNN(K-최근접 이웃)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzOlxPpy9qA4"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN Regressor** : 주변의 가장 가까운 K개의 샘플을 통해 값을 예측하는 방식 입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 회귀 모델 학습 - KNN Regressor\n",
    "\n",
    " KNN 회귀 모델을 학습시켜보겠습니다. 데이터의 변수명이 저희가 정의한 변수명과 다를 경우, 이를 조절해줍시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주요 파라미터\n",
    "\n",
    "- n_neighbors: 이웃의 수를 결정합니다. 예측 시 가장 가까운 n_neighbors개의 이웃의 값을 평균하여 예측 값을 계산합니다. 기본값은 5입니다.\n",
    "- weights: 이웃의 가중치를 설정합니다. uniform이면 모든 이웃이 동일한 가중치를 가지며, distance로 설정하면 가까운 이웃일수록 더 큰 가중치를 가집니다.\n",
    "- algorithm: 이웃을 찾는 데 사용할 알고리즘을 선택합니다. auto는 최적의 알고리즘을 자동으로 선택하며, 다른 옵션으로는 ball_tree, kd_tree, brute가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# KNN 회귀 모델 정의\n",
    "knn = KNeighborsRegressor(n_neighbors=5, weights='uniform', algorithm='auto')\n",
    "\n",
    "# 모델 학습\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# 결정 계수 계산\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# 평균 제곱근 오차 계산\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"결정 계수:\", r2)\n",
    "print(\"평균 제곱근 오차:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가를 마친 이후, 시각화 코드를 통해 실제값과 예측값의 차이를 확인해봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1660701173689,
     "user": {
      "displayName": "장혜성",
      "userId": "05362368838194112032"
     },
     "user_tz": -540
    },
    "id": "0eqWTuM2p_9B",
    "outputId": "df0656ff-be6a-46ce-9aa3-55f4cde2a08c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 모델의 출력값\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 그래프로 시각화\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--', lw=2)  # 일치하는 직선\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs. Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cosGnk6q-8CD"
   },
   "source": [
    "### 서포트벡터머신(SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htvN3YS8__49"
   },
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ng5rbONCBAzJ"
   },
   "source": [
    "**서포트벡터머신(SVM)** : 주어진 데이터 집합을 바탕으로 하여 새로운 데이터가 어느 카테고리에 속할지 판단하는 비확률적 이진 선형 분류 모델을 만드며, 만들어진 분류 모델은 데이터가 사상된 공간에서 경계로 표현되는데 SVM 알고리즘은 그 중 가장 큰 폭을 가진 경계를 찾는 방식입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56aW8OfrAR5q"
   },
   "source": [
    "주요 파라미터\n",
    "\n",
    "- kernel: 커널 함수의 종류를 지정합니다. 'linear', 'poly', 'rbf', 'sigmoid' 중 선택할 수 있으며, rbf가 기본값입니다.\n",
    "- C: 오류에 대한 패널티를 조절하는 파라미터입니다. 값이 클수록 모델은 낮은 오류를 목표로 하며, 과적합의 가능성이 높아집니다.\n",
    "- epsilon: 결정 경계 안에서 오류를 무시할 수 있는 마진을 설정합니다. 값이 클수록 모델이 더 유연해집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 회귀 모델 학습 - SVM\n",
    "\n",
    "SVN을 학습시켜보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# SVM 회귀 모델 정의\n",
    "svm_regressor = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "\n",
    "# 모델 학습\n",
    "svm_regressor.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = svm_regressor.predict(X_test)\n",
    "\n",
    "# 결정 계수 계산\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# 평균 제곱근 오차 계산\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"결정 계수: \", r2)\n",
    "print(\"평균 제곱근 오차: \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가를 마친 이후, 시각화 코드를 통해 실제값과 예측값의 차이를 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "executionInfo": {
     "elapsed": 459,
     "status": "ok",
     "timestamp": 1660701174142,
     "user": {
      "displayName": "장혜성",
      "userId": "05362368838194112032"
     },
     "user_tz": -540
    },
    "id": "WB6d5-9VAxXl",
    "outputId": "8c79867b-422f-4dbd-e07f-a16e62fa9e5e"
   },
   "outputs": [],
   "source": [
    "# 그래프 그리기\n",
    "plt.scatter(y_test, y_pred, color='blue', label='Predicted')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', label='Ideal')\n",
    "plt.xlabel('Actual Value')\n",
    "plt.ylabel('Predicted Value')\n",
    "plt.title('Distribution of Predicted Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpAbltLBA7k_"
   },
   "source": [
    "### AdaBoost(Adaptive Boost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5Q02c-fCSP_"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OAttmw3DTHY"
   },
   "source": [
    "**Adaptive Boost** : Adaptive + Boosting 로 만들어진 단어로 약한 분류기(weak classifier)들이 상호보완 하도록 순차적(sequential)으로 학습하고, 이들을 조합하여 최종적으로 강한 분류기(strong classifier)의 성능을 향상시키는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 회귀 모델 학습 - AdaBoost\n",
    "\n",
    "코드를 사용해서 선형 회귀 모델을 학습시켜보겠습니다. 데이터의 변수명이 저희가 정의한 변수명과 다를 경우, 이를 조절해줍시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주요 파라미터\n",
    "\n",
    "- n_estimators: 기본 추정기(weak learners)의 개수를 지정합니다. 기본값은 50이며, 값이 커질수록 모델의 복잡도가 증가합니다.\n",
    "- learning_rate: 각 추정기에 적용되는 가중치를 조정하는 학습률입니다. 값이 작을수록 각 단계의 기여가 줄어들며, 값이 크면 더 빠르게 학습하지만 과적합의 가능성이 높아집니다.\n",
    "- loss: 손실 함수의 종류를 지정합니다. 'linear', 'square', 'exponential' 중에서 선택할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# AdaBoost 회귀 모델 정의\n",
    "model = AdaBoostRegressor(n_estimators=50, learning_rate=1.0, loss='linear')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 결정 계수 계산\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# 평균 제곱근 오차 계산\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"결정 계수:\", r2)\n",
    "print(\"평균 제곱근 오차:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가를 마친 이후, 시각화 코드를 통해 실제값과 예측값의 차이를 확인해봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "executionInfo": {
     "elapsed": 455,
     "status": "ok",
     "timestamp": 1660701174594,
     "user": {
      "displayName": "장혜성",
      "userId": "05362368838194112032"
     },
     "user_tz": -540
    },
    "id": "c4Vd3AROC-z5",
    "outputId": "5519d68b-c62e-43d0-e8cc-315a1054020f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 모델의 출력값\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 그래프로 시각화\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--', lw=2)  # 일치하는 직선\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs. Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-f33BOj4DooT"
   },
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCeT4SkuEQN1"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLV0z3E8ERP8"
   },
   "source": [
    "**배깅(Bagging)** : Bootstrap Aggregation의 약자로 샘플을 여러 번 뽑아 각 모델을 학습시켜 결과물을 집계하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 회귀 모델 학습 - bagging\n",
    "\n",
    "Bagging 모델을 학습시켜보겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주요 파라미터\n",
    "\n",
    "- n_estimators: 사용할 기본 추정기(weak learners)의 개수를 지정합니다. 기본값은 10입니다. 이 값이 클수록 예측 성능이 향상될 수 있지만, 계산 비용이 증가합니다.\n",
    "- max_samples: 각 기본 추정기가 학습할 때 사용할 샘플의 비율을 지정합니다. 기본값은 1.0으로, 전체 데이터셋을 사용합니다.\n",
    "- bootstrap: 샘플링할 때 중복을 허용할지 여부를 설정합니다. True이면 중복을 허용하고, False이면 중복 없이 샘플링합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1660701174595,
     "user": {
      "displayName": "장혜성",
      "userId": "05362368838194112032"
     },
     "user_tz": -540
    },
    "id": "4ISF29RaDM_T",
    "outputId": "fdc036a5-ec92-498f-bef8-6e26d9e90bfe"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Bagging 회귀 모델 정의\n",
    "bagging_model = BaggingRegressor()\n",
    "\n",
    "# 모델 학습\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred = bagging_model.predict(X_test)\n",
    "\n",
    "# 결정 계수 계산\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# 평균 제곱근 오차 계산\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"결정 계수:\", r2)\n",
    "print(\"평균 제곱근 오차:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가를 마친 이후, 시각화 코드를 통해 실제값과 예측값의 차이를 확인해봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1660701174595,
     "user": {
      "displayName": "장혜성",
      "userId": "05362368838194112032"
     },
     "user_tz": -540
    },
    "id": "VbuQ-TZ9D9uO",
    "outputId": "e897f58d-2c09-42c7-de99-08a04460b572"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 모델의 출력값\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 그래프로 시각화\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--', lw=2)  # 일치하는 직선\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs. Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 의사 결정 나무 (Decision Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 회귀 모델 학습 - Decision Tree\n",
    "\n",
    "Decision Tree 모델을 학습시켜보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주요 파라미터\n",
    "\n",
    "- max_depth: 트리의 최대 깊이를 설정합니다. 이 값이 작을수록 트리가 덜 복잡해지고, 과적합을 방지할 수 있습니다.\n",
    "- min_samples_split: 내부 노드를 분할하는 데 필요한 최소 샘플 수를 지정합니다. 값이 클수록 트리가 더 적게 분할되며, 과적합을 방지할 수 있습니다.\n",
    "- min_samples_leaf: 리프 노드에 있어야 하는 최소 샘플 수를 지정합니다. 값이 클수록 리프 노드가 더 크고, 트리의 복잡성이 줄어듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Decision Tree 회귀 모델 정의\n",
    "model = DecisionTreeRegressor(max_depth=None, min_samples_split=2, min_samples_leaf=1)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 결정 계수 계산\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# 평균 제곱근 오차 계산\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"결정 계수:\", r2)\n",
    "print(\"평균 제곱근 오차:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가를 마친 이후, 시각화 코드를 통해 실제값과 예측값의 차이를 확인해봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 모델의 출력값\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 그래프로 시각화\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--', lw=2)  # 일치하는 직선\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs. Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Zj2P4ksGFLE"
   },
   "source": [
    "### 랜덤 포레스트 (RandomForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-b3IcGUzGL_j"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKlPCERiGGIx"
   },
   "source": [
    "**랜덤포레스트** : 분류, 회귀 분석 등에 사용되는 앙상블 학습 방법의 일종으로, 훈련 과정에서 구성한 다수의 결정 트리로부터 분류 또는 회귀 분석을 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 회귀 모델 학습 - RandomForest\n",
    "\n",
    "RandomForest 모델을 학습시켜보겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주요 파라미터\n",
    "\n",
    "- n_estimators: 사용할 결정 트리의 개수를 지정합니다. 이 값이 클수록 성능이 향상될 수 있지만 계산 비용이 증가합니다.\n",
    "- max_depth: 각 트리의 최대 깊이를 설정합니다. 값을 설정하지 않으면 트리는 완전히 분할될 때까지 성장합니다.\n",
    "- max_features: 각 트리에서 분할할 때 고려할 최대 특성 수를 설정합니다. 'auto', 'sqrt', 'log2' 등이 있습니다. 이는 모델의 다양성을 높여 성능을 개선할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1660701174595,
     "user": {
      "displayName": "장혜성",
      "userId": "05362368838194112032"
     },
     "user_tz": -540
    },
    "id": "UYFpnjlWGFjR",
    "outputId": "79f5f7e9-8587-49b0-ab2e-a3a34e83df0d"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Random Forest 회귀 모델 정의\n",
    "model = RandomForestRegressor(n_estimators=100, max_depth=None, max_features='auto')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 결정 계수 계산\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# 평균 제곱근 오차 계산\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"결정 계수:\", r2)\n",
    "print(\"평균 제곱근 오차:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가를 마친 이후, 시각화 코드를 통해 실제값과 예측값의 차이를 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 627,
     "status": "ok",
     "timestamp": 1660701175216,
     "user": {
      "displayName": "장혜성",
      "userId": "05362368838194112032"
     },
     "user_tz": -540
    },
    "id": "RwRqHaUYGRuA",
    "outputId": "c6d07e45-3e02-4739-aa2c-bbc77a4a0b0f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 모델의 출력값\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 그래프로 시각화\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--', lw=2)  # 일치하는 직선\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs. Predicted Values')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "day3_정답_코드.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "258a73f1c669c2347e4e02ca349ba9be5513ea940fd96db1ccad27dbf575ba85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
